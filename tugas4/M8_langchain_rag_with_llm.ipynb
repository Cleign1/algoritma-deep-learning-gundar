{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a RAG model with Langchain and Openrouter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kelompok 1 Algoritma Deep Learning\n",
    "Anggota Kelompok :\n",
    "1. A IAS Falah Surya Gemilang\n",
    "2. Aldo Rizky Ramadhan\n",
    "3. Faiz Rizki Azmi\n",
    "4. Muhamad Ibnu Khaidar Hafiz\n",
    "5. Siti Asma Tomu"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T13:50:32.396410Z",
     "start_time": "2024-11-17T13:50:13.668397Z"
    }
   },
   "source": [
    "## install langchain\n",
    "# %pip install langchain langchain-openai langchain-chroma beautifulsoup4\n",
    "# %pip install chromadb \n",
    "# %pip install langchain-nvidia-ai-endpoints\n",
    "# %pip install \"unstructured[md]\" nltk"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting unstructured[md]\n",
      "  Downloading unstructured-0.16.5-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting chardet (from unstructured[md])\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filetype (from unstructured[md])\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured[md])\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting lxml (from unstructured[md])\n",
      "  Downloading lxml-5.3.0-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: requests in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from unstructured[md]) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from unstructured[md]) (4.12.3)\n",
      "Collecting emoji (from unstructured[md])\n",
      "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: dataclasses-json in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from unstructured[md]) (0.6.7)\n",
      "Collecting python-iso639 (from unstructured[md])\n",
      "  Downloading python_iso639-2024.10.22-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langdetect (from unstructured[md])\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     -------------------- ----------------- 524.3/981.5 kB 3.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 981.5/981.5 kB 2.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy<2 in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from unstructured[md]) (1.26.4)\n",
      "Collecting rapidfuzz (from unstructured[md])\n",
      "  Downloading rapidfuzz-3.10.1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: backoff in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from unstructured[md]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from unstructured[md]) (4.12.2)\n",
      "Collecting unstructured-client (from unstructured[md])\n",
      "  Downloading unstructured_client-0.27.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wrapt in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from unstructured[md]) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from unstructured[md]) (4.67.0)\n",
      "Requirement already satisfied: psutil in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from unstructured[md]) (6.1.0)\n",
      "Collecting python-oxmsg (from unstructured[md])\n",
      "  Downloading python_oxmsg-0.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured[md])\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting markdown (from unstructured[md])\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: click in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from beautifulsoup4->unstructured[md]) (2.6)\n",
      "Requirement already satisfied: colorama in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from dataclasses-json->unstructured[md]) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from dataclasses-json->unstructured[md]) (0.9.0)\n",
      "Requirement already satisfied: six>=1.9 in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from html5lib->unstructured[md]) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from html5lib->unstructured[md]) (0.5.1)\n",
      "Collecting olefile (from python-oxmsg->unstructured[md])\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from requests->unstructured[md]) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from requests->unstructured[md]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from requests->unstructured[md]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from requests->unstructured[md]) (2024.8.30)\n",
      "Collecting cryptography>=3.1 (from unstructured-client->unstructured[md])\n",
      "  Downloading cryptography-43.0.3-cp39-abi3-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting eval-type-backport<0.3.0,>=0.2.0 (from unstructured-client->unstructured[md])\n",
      "  Downloading eval_type_backport-0.2.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from unstructured-client->unstructured[md]) (0.27.2)\n",
      "Collecting jsonpath-python<2.0.0,>=1.0.6 (from unstructured-client->unstructured[md])\n",
      "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from unstructured-client->unstructured[md]) (1.6.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.9.2 in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from unstructured-client->unstructured[md]) (2.9.2)\n",
      "Collecting pypdf>=4.0 (from unstructured-client->unstructured[md])\n",
      "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting python-dateutil==2.8.2 (from unstructured-client->unstructured[md])\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from unstructured-client->unstructured[md]) (1.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from cryptography>=3.1->unstructured-client->unstructured[md]) (1.17.1)\n",
      "Requirement already satisfied: anyio in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from httpx>=0.27.0->unstructured-client->unstructured[md]) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from httpx>=0.27.0->unstructured-client->unstructured[md]) (1.0.7)\n",
      "Requirement already satisfied: sniffio in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from httpx>=0.27.0->unstructured-client->unstructured[md]) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured[md]) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured[md]) (24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from pydantic<2.10.0,>=2.9.2->unstructured-client->unstructured[md]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from pydantic<2.10.0,>=2.9.2->unstructured-client->unstructured[md]) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured[md]) (1.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\codes\\algoritma-deep-learning-gundar\\venv\\lib\\site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured[md]) (2.22)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.5 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 3.2 MB/s eta 0:00:00\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
      "   ---------------------------------------- 0.0/586.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 586.9/586.9 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading lxml-5.3.0-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.5/3.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.0/3.8 MB 3.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.1/3.8 MB 3.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.6/3.8 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.1/3.8 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 3.2 MB/s eta 0:00:00\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading python_iso639-2024.10.22-py3-none-any.whl (274 kB)\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.1-py3-none-any.whl (31 kB)\n",
      "Downloading rapidfuzz-3.10.1-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 3.0 MB/s eta 0:00:00\n",
      "Downloading unstructured-0.16.5-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.7 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 3.4 MB/s eta 0:00:00\n",
      "Downloading unstructured_client-0.27.0-py3-none-any.whl (59 kB)\n",
      "Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Downloading cryptography-43.0.3-cp39-abi3-win_amd64.whl (3.1 MB)\n",
      "   ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.5/3.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.3/3.1 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.8/3.1 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.6/3.1 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.1/3.1 MB 3.4 MB/s eta 0:00:00\n",
      "Downloading eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993254 sha256=164131de35167afb7ba820a69a18730724be7c6433c6c24cf785982466f343fa\n",
      "  Stored in directory: c:\\users\\ibnuk\\appdata\\local\\pip\\cache\\wheels\\0a\\f2\\b2\\e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
      "Successfully built langdetect\n",
      "Installing collected packages: filetype, rapidfuzz, python-magic, python-iso639, python-dateutil, pypdf, olefile, markdown, lxml, langdetect, jsonpath-python, html5lib, eval-type-backport, emoji, chardet, python-oxmsg, nltk, cryptography, unstructured-client, unstructured\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "Successfully installed chardet-5.2.0 cryptography-43.0.3 emoji-2.14.0 eval-type-backport-0.2.0 filetype-1.2.0 html5lib-1.1 jsonpath-python-1.0.6 langdetect-1.0.9 lxml-5.3.0 markdown-3.7 nltk-3.9.1 olefile-0.47 pypdf-5.1.0 python-dateutil-2.8.2 python-iso639-2024.10.22 python-magic-0.4.27 python-oxmsg-0.0.1 rapidfuzz-3.10.1 unstructured-0.16.5 unstructured-client-0.27.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T14:08:21.436214Z",
     "start_time": "2024-11-17T14:08:09.935425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First Cell - Imports and Setup\n",
    "import getpass\n",
    "import os\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader, DirectoryLoader, UnstructuredMarkdownLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up NVIDIA API key\n",
    "os.environ[\"NVIDIA_API_KEY\"] = getpass.getpass(\"Enter your NVIDIA API key: \")\n",
    "\n",
    "# Initialize NVIDIA LLM\n",
    "llm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T14:09:15.741822Z",
     "start_time": "2024-11-17T14:09:15.737488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Second Cell - Document Loading Functions\n",
    "def load_markdown_documents(directory_path: str) -> List:\n",
    "    \"\"\"\n",
    "    Load markdown documents from a directory\n",
    "    \"\"\"\n",
    "    loader = DirectoryLoader(\n",
    "        directory_path,\n",
    "        glob=\"**/*.md\",\n",
    "        loader_cls=UnstructuredMarkdownLoader\n",
    "    )\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "def load_web_content(urls: List[str]) -> List:\n",
    "    \"\"\"\n",
    "    Load content from web URLs\n",
    "    \"\"\"\n",
    "    loader = WebBaseLoader(\n",
    "        web_paths=urls,\n",
    "        bs_kwargs=dict(\n",
    "            parse_only=bs4.SoupStrainer(\n",
    "                class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    documents = loader.load()\n",
    "    return documents"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T14:09:26.941867Z",
     "start_time": "2024-11-17T14:09:26.937099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Third Cell - Text Splitting\n",
    "def split_documents(documents: List) -> List:\n",
    "    \"\"\"\n",
    "    Split documents into chunks\n",
    "    \"\"\"\n",
    "    # For markdown documents\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"Header 1\"),\n",
    "        (\"##\", \"Header 2\"),\n",
    "        (\"###\", \"Header 3\"),\n",
    "    ]\n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "    \n",
    "    # General text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    splits = []\n",
    "    for doc in documents:\n",
    "        # Try markdown splitting first\n",
    "        try:\n",
    "            header_splits = markdown_splitter.split_text(doc.page_content)\n",
    "            text_splits = text_splitter.split_documents(header_splits)\n",
    "        except:\n",
    "            # Fall back to regular splitting if not markdown\n",
    "            text_splits = text_splitter.split_documents([doc])\n",
    "        splits.extend(text_splits)\n",
    "    \n",
    "    return splits\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T14:10:08.365208Z",
     "start_time": "2024-11-17T14:10:08.361174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fourth Cell - Vector Store Creation\n",
    "def create_vector_store(documents: List):\n",
    "    \"\"\"\n",
    "    Create and return a vector store from the documents\n",
    "    \"\"\"\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"all-MiniLM-L6-v2\",\n",
    "        model_kwargs={'device': 'cuda'},\n",
    "        encode_kwargs={'device': 'cuda', 'batch_size': 32}\n",
    "    )\n",
    "    \n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=\"./chroma_db\"\n",
    "    )\n",
    "    \n",
    "    return vector_store\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T14:10:23.395043Z",
     "start_time": "2024-11-17T14:10:23.391009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fifth Cell - RAG Chain Creation\n",
    "def create_rag_chain(vector_store):\n",
    "    \"\"\"\n",
    "    Create and return a RAG chain\n",
    "    \"\"\"\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\n",
    "            \"k\": 5,\n",
    "            \"fetch_k\": 10\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "    # Get the RAG prompt from LangChain hub\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "    \n",
    "    # Create the RAG chain\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    return rag_chain\n"
   ],
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
